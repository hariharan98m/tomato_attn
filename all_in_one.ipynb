{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow, keras\n",
    "import keras\n",
    "from keras.layers import merge, Conv2D, Input, Reshape, Activation\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from numpy import genfromtxt\n",
    "from keras.preprocessing.image import img_to_array as img_to_array\n",
    "from keras.preprocessing.image import load_img as load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essentials\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(input_shape):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # First Block\n",
    "    #CONV layer\n",
    "    X = Conv2D(32, (7, 7), strides = (1,1), activation='relu', padding='same')(X_input)\n",
    "    # MAXPOOL + BatchNorm\n",
    "    X = MaxPooling2D((2,2), strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Second Block\n",
    "    #CONV layer\n",
    "    X = Conv2D(64, (5, 5), strides = (2,2), activation='relu', padding='same')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2,2), strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Third Block\n",
    "    X = Conv2D(128, (5,5), strides = (1, 1),activation='relu', padding='same')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Top layer\n",
    "    X = AveragePooling2D(pool_size=(2,2), strides=(2,2))(X)\n",
    "    X = Conv2D(64, (7,7), strides = (2,2),activation='relu')(X)\n",
    "    \n",
    "    # L2 normalization\n",
    "    X = Lambda(lambda  x: K.l2_normalize(x,axis=-1))(X)\n",
    "\n",
    "    #Final output layer. First Unit is a sigmoid act(whether seen img is infected/not)\n",
    "    # next 2 units for identifying type of infection if 1st element is 1. otherwise, don't care.\n",
    "    \n",
    "    infected = Conv2D(2, (1, 1), strides = (1,1),activation='softmax')(X)\n",
    "    infection_type = Conv2D(3, (1, 1), strides = (1,1),activation='softmax')(X)\n",
    "    \n",
    "    infected= Reshape((2,))(infected)\n",
    "    infection_type= Reshape((3,))(infection_type)\n",
    "    # Create model instance\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = (infected, infection_type))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= ConvNet((256,256,3))\n",
    "c.load_weights('checkpointSave.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 13s 134ms/step - loss: -0.1614 - reshape_1_loss: -0.1329 - reshape_2_loss: -0.0285 - reshape_1_acc: 0.4900 - reshape_2_acc: 0.3000\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s 4ms/step - loss: -1.2357 - reshape_1_loss: -0.5186 - reshape_2_loss: -0.7172 - reshape_1_acc: 0.8400 - reshape_2_acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "m=100\n",
    "\n",
    "Xtrain= np.random.randn(m, 256, 256, 3)\n",
    "y1train = np.random.randn(m, 2)\n",
    "y2train = np.random.randn(m, 3)\n",
    "\n",
    "\n",
    "y = [y1train, y2train]\n",
    "\n",
    "\n",
    "##Using the GPU\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    c.fit(x= Xtrain, y=y, epochs=2, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, size=256):\n",
    "    # data augmentation logic such as random rotations can be added here\n",
    "    return img_to_array(load_img(image_path, target_size=(size, size, 3))) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfectedLeavesSequence(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, X, y1, y2, batch_size=512, dim=(256,256), n_channels=3, shuffle=True):\n",
    "        #Initialization\n",
    "        self.dim = dim\n",
    "        self.X= X\n",
    "        self.y1= y1\n",
    "        self.y2= y2\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        batched_image_names = [self.X[k] for k in indexes]\n",
    "        batched_y1 = self.y1[indexes]\n",
    "        batched_y2 = self.y2[indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        X = self.__data_generation(batched_image_names)\n",
    "        \n",
    "        return X, [batched_y1, batched_y2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, images):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(images):\n",
    "            # Store sample\n",
    "            X[i,:, :, :] = load_image('data_images/Archive/'+ID)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df_path='infectedLeaves.csv', n_classes1= 2, n_classes2= 3):\n",
    "    df = pd.read_csv(df_path)\n",
    "    #resolve priyanka's error.\n",
    "    df['infectionType']= df['infectionType'].map({0: 0, 1:1, 2:2, 4:3})\n",
    "    #create categorical quants\n",
    "    y1= keras.utils.to_categorical(df['infected'], num_classes=n_classes1)\n",
    "    y2= keras.utils.to_categorical(df['infectionType'], num_classes=n_classes2+1)\n",
    "    #drop final axis=-1 last dim of y2\n",
    "    y2= y2[:, :3]\n",
    "    #final images list names\n",
    "    X = df['pathName'].values\n",
    "    return df, X, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X, y1, y2= prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred, N = 128, beta=128, epsilon=1e-8):\n",
    "    \n",
    "    infected, infection_type = y_pred[0], y_pred[1]\n",
    "    \n",
    "    # loss for either layers\n",
    "    infected_loss = tf.losses.softmax_cross_entropy(y_true[0], infected)\n",
    "    infection_type_loss = tf.losses.softmax_cross_entropy(y_true[1], infection_type)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = 0.25*infected_loss + 0.75*infection_type_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 4736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   51264       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 128)  204928      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 64)     401472      average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1, 64)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 2)      130         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1, 1, 3)      195         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2)            0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 3)            0           conv2d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 663,621\n",
      "Trainable params: 663,173\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Training on fold 1/5...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 366, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 240, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 233, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/context.py\", line 267, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/popen_fork.py\", line 67, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 553, in _terminate_pool\n",
      "    p.terminate()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 113, in terminate\n",
      "    self._popen.terminate()\n",
      "AttributeError: 'NoneType' object has no attribute 'terminate'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'model/fold1.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaybeEncodingError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8af0f9115553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                         )\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaybeEncodingError\u001b[0m: Error sending result: '(array([[[[0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         ...,\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314]],\n\n        [[0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         ...,\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314]],\n\n        [[0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         [0.39215687, 0.50196081, 0.30980393],\n         ...,\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314],\n         [0.40392157, 0.50980395, 0.20784314]],\n\n        ...,\n\n        [[0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         ...,\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982]],\n\n        [[0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         ...,\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982]],\n\n        [[0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         [0.54901963, 0.52156866, 0.59215689],\n         ...,\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982],\n         [0.35294119, 0.47058824, 0.27450982]]],\n\n\n       [[[0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         ...,\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552]],\n\n        [[0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         ...,\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552]],\n\n        [[0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         [0.49803922, 0.43921569, 0.52941179],\n         ...,\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552],\n         [0.56862748, 0.65490198, 0.51372552]],\n\n        ...,\n\n        [[0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         ...,\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157]],\n\n        [[0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         ...,\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157]],\n\n        [[0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         [0.627451  , 0.70980394, 0.58039218],\n         ...,\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157],\n         [0.09411765, 0.18431373, 0.00392157]]],\n\n\n       [[[0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         ...,\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ]],\n\n        [[0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         ...,\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ]],\n\n        [[0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         [0.20392157, 0.29019609, 0.27843139],\n         ...,\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ],\n         [0.50588238, 0.51764709, 0.5529412 ]],\n\n        ...,\n\n        [[0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         ...,\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866]],\n\n        [[0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         ...,\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866]],\n\n        [[0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         [0.49019608, 0.48235294, 0.50196081],\n         ...,\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866],\n         [0.50980395, 0.50196081, 0.52156866]]],\n\n\n       ...,\n\n\n       [[[0.78823531, 0.7764706 , 0.81960785],\n         [0.78823531, 0.7764706 , 0.81960785],\n         [0.63529414, 0.62352943, 0.66666669],\n         ...,\n         [0.66666669, 0.65098041, 0.70588237],\n         [0.41568628, 0.40000001, 0.45490196],\n         [0.41568628, 0.40000001, 0.45490196]],\n\n        [[0.78823531, 0.7764706 , 0.81960785],\n         [0.78823531, 0.7764706 , 0.81960785],\n         [0.63529414, 0.62352943, 0.66666669],\n         ...,\n         [0.66666669, 0.65098041, 0.70588237],\n         [0.41568628, 0.40000001, 0.45490196],\n         [0.41568628, 0.40000001, 0.45490196]],\n\n        [[0.47843137, 0.46666667, 0.50980395],\n         [0.47843137, 0.46666667, 0.50980395],\n         [0.47450981, 0.4627451 , 0.50588238],\n         ...,\n         [0.82745099, 0.81176472, 0.86666667],\n         [0.70588237, 0.6901961 , 0.74509805],\n         [0.70588237, 0.6901961 , 0.74509805]],\n\n        ...,\n\n        [[0.01960784, 0.03137255, 0.        ],\n         [0.01960784, 0.03137255, 0.        ],\n         [0.15294118, 0.16470589, 0.09803922],\n         ...,\n         [0.54901963, 0.63921571, 0.47450981],\n         [0.4627451 , 0.5529412 , 0.3882353 ],\n         [0.4627451 , 0.5529412 , 0.3882353 ]],\n\n        [[0.22745098, 0.23529412, 0.18039216],\n         [0.22745098, 0.23529412, 0.18039216],\n         [0.09411765, 0.10588235, 0.03921569],\n         ...,\n         [0.33333334, 0.42352942, 0.25882354],\n         [0.24705882, 0.33725491, 0.17254902],\n         [0.24705882, 0.33725491, 0.17254902]],\n\n        [[0.22745098, 0.23529412, 0.18039216],\n         [0.22745098, 0.23529412, 0.18039216],\n         [0.09411765, 0.10588235, 0.03921569],\n         ...,\n         [0.33333334, 0.42352942, 0.25882354],\n         [0.24705882, 0.33725491, 0.17254902],\n         [0.24705882, 0.33725491, 0.17254902]]],\n\n\n       [[[0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         ...,\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608]],\n\n        [[0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         ...,\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608]],\n\n        [[0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         [0.34901962, 0.47450981, 0.21960784],\n         ...,\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608],\n         [0.52549022, 0.45882353, 0.49019608]],\n\n        ...,\n\n        [[0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         ...,\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707]],\n\n        [[0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         ...,\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707]],\n\n        [[0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         [0.39215687, 0.34117648, 0.36862746],\n         ...,\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707],\n         [0.34901962, 0.3019608 , 0.31764707]]],\n\n\n       [[[0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         ...,\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471]],\n\n        [[0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         ...,\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471]],\n\n        [[0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         [0.63921571, 0.73333335, 0.53725493],\n         ...,\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471],\n         [0.43529412, 0.5411765 , 0.41176471]],\n\n        ...,\n\n        [[0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         ...,\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981]],\n\n        [[0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         ...,\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981]],\n\n        [[0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         [0.08235294, 0.17254902, 0.00784314],\n         ...,\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981],\n         [0.45882353, 0.60392159, 0.47450981]]]]), [array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       ...,\n       [1., 0.],\n       [0., 1.],\n       [0., 1.]], dtype=float32), array([[0., 0., 1.],\n       [0., 0., 0.],\n       [0., 1., 0.],\n       ...,\n       [0., 0., 0.],\n       [1., 0., 0.],\n       [0., 1., 0.]], dtype=float32)])'. Reason: 'MemoryError()'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8af0f9115553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/fold'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'model/fold1.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cvscores = []\n",
    "\n",
    "##Setting up the path for saving logs\n",
    "logs_path = job_dir + 'logs/tensorboard'\n",
    "\n",
    "##Using the GPU\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    ## Initializing the model\n",
    "    model = ConvNet((256, 256, 3))\n",
    "\n",
    "    ## Compling the model\n",
    "    model.compile(optimizer = \"adam\" , loss = loss, metrics = [\"accuracy\"]);\n",
    "\n",
    "    ## Printing the modle summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    # Loop through the indices the split() method returns\n",
    "    for index, (train_indices, val_indices) in enumerate(kfold.split(X, df['infectionType'])):\n",
    "        if (index==1): \n",
    "            break\n",
    "        print(\"Training on fold \" + str(index+1) + \"/5...\")\n",
    "        m_train= len(train_indices)\n",
    "        m_val= len(val_indices)\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y1_train, y1_val = y1[train_indices], y1[val_indices]\n",
    "        y2_train, y2_val = y2[train_indices], y2[val_indices]\n",
    "        \n",
    "        train_seq = InfectedLeavesSequence(X_train, y1_train, y2_train)\n",
    "        val_seq = InfectedLeavesSequence(X_val, y1_val, y2_val)\n",
    "\n",
    "        try:\n",
    "            hist= model.fit_generator(generator=train_seq,\n",
    "                        validation_data=val_seq,\n",
    "                        epochs= 40,\n",
    "                        \n",
    "                        )\n",
    "        \n",
    "            print(hist.history)\n",
    "        except: \n",
    "            #save model\n",
    "            model.save('model/fold'+str(index+1)+'.h5')    \n",
    "        \n",
    "        scores = model.evaluate(X_val, y_val)\n",
    "        \n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        cvscores.append(scores[1] * 100)\n",
    "        \n",
    "        #save model\n",
    "        model.save('model_fold'+(index+1)+'.h5')\n",
    "    #final accuracy\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow, keras\n",
    "import keras\n",
    "from keras.layers import merge, Conv2D, Input, Reshape, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from numpy import genfromtxt\n",
    "from keras.preprocessing.image import img_to_array as img_to_array\n",
    "from keras.preprocessing.image import load_img as load_img\n",
    "\n",
    "#essentials\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from keras import callbacks\n",
    "\n",
    "def ConvNet(input_shape):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # First Block\n",
    "    #CONV layer\n",
    "    X = Conv2D(32, (7, 7), strides = (1,1), activation='relu', padding='same')(X_input)\n",
    "    # MAXPOOL + BatchNorm\n",
    "    X = MaxPooling2D((2,2), strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Second Block\n",
    "    #CONV layer\n",
    "    X = Conv2D(64, (5, 5), strides = (2,2), activation='relu', padding='same')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2,2), strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Third Block\n",
    "    X = Conv2D(128, (5,5), strides = (1, 1),activation='relu', padding='same')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2, padding='same')(X)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    \n",
    "    # Top layer\n",
    "    X = AveragePooling2D(pool_size=(2,2), strides=(2,2))(X)\n",
    "    X = Conv2D(64, (7,7), strides = (2,2),activation='relu')(X)\n",
    "    \n",
    "    # L2 normalization\n",
    "    X = Lambda(lambda  x: K.l2_normalize(x,axis=-1))(X)\n",
    "\n",
    "    #Final output layer. First Unit is a sigmoid act(whether seen img is infected/not)\n",
    "    # next 2 units for identifying type of infection if 1st element is 1. otherwise, don't care.\n",
    "    \n",
    "    infected = Conv2D(2, (1, 1), strides = (1,1),activation='softmax')(X)\n",
    "    infection_type = Conv2D(3, (1, 1), strides = (1,1),activation='softmax')(X)\n",
    "    \n",
    "    infected= Reshape((2,))(infected)\n",
    "    infection_type= Reshape((3,))(infection_type)\n",
    "    # Create model instance\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = (infected, infection_type))\n",
    "    \n",
    "    return model\n",
    "\n",
    "m=100\n",
    "\n",
    "Xtrain= np.random.randn(m, 256, 256, 3)\n",
    "y1train = np.random.randn(m, 2)\n",
    "y2train = np.random.randn(m, 3)\n",
    "\n",
    "\n",
    "y = [y1train, y2train]\n",
    "\n",
    "c= ConvNet((256,256,3))\n",
    "c.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]);\n",
    "\n",
    "##Using the GPU\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    c.fit(x= Xtrain, y=y, epochs=2, batch_size=25)\n",
    "\n",
    "def load_image(image_path, size=256):\n",
    "    # data augmentation logic such as random rotations can be added here\n",
    "    return img_to_array(load_img(image_path, target_size=(size, size, 3))) / 255.\n",
    "\n",
    "class InfectedLeavesSequence(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, X, y1, y2, batch_size=512, dim=(256,256), n_channels=3, shuffle=True):\n",
    "        #Initialization\n",
    "        self.dim = dim\n",
    "        self.X= X\n",
    "        self.y1= y1\n",
    "        self.y2= y2\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        batched_image_names = [self.X[k] for k in indexes]\n",
    "        batched_y1 = self.y1[indexes]\n",
    "        batched_y2 = self.y2[indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        X = self.__data_generation(batched_image_names)\n",
    "        \n",
    "        return X, [batched_y1, batched_y2]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, images):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(images):\n",
    "            # Store sample\n",
    "            X[i,:, :, :] = load_image('data_images/Archive/'+ID)\n",
    "\n",
    "        return X\n",
    "\n",
    "job_dir = ''\n",
    "\n",
    "random.seed(0)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def prep_data(df_path='infectedLeaves.csv', n_classes1= 2, n_classes2= 3):\n",
    "    df = pd.read_csv(df_path)\n",
    "    #resolve priyanka's error.\n",
    "    df['infectionType']= df['infectionType'].map({0: 0, 1:1, 2:2, 4:3})\n",
    "    #create categorical quants\n",
    "    y1= keras.utils.to_categorical(df['infected'], num_classes=n_classes1)\n",
    "    y2= keras.utils.to_categorical(df['infectionType'], num_classes=n_classes2+1)\n",
    "    #drop final axis=-1 last dim of y2\n",
    "    y2= y2[:, :3]\n",
    "    #final images list names\n",
    "    X = df['pathName'].values\n",
    "    return df, X, y1, y2\n",
    "\n",
    "df, X, y1, y2= prep_data()\n",
    "\n",
    "def loss(y_true, y_pred, N = 128, beta=128, epsilon=1e-8):\n",
    "    \n",
    "    infected, infection_type = y_pred[0], y_pred[1]\n",
    "    \n",
    "    # loss for either layers\n",
    "    infected_loss = tf.losses.softmax_cross_entropy(y_true[0], infected)\n",
    "    infection_type_loss = tf.losses.softmax_cross_entropy(y_true[1], infection_type)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = 0.25*infected_loss + 0.75*infection_type_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cvscores = []\n",
    "\n",
    "##Setting up the path for saving logs\n",
    "logs_path = job_dir + 'logs/tensorboard'\n",
    "\n",
    "##Using the GPU\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    ## Initializing the model\n",
    "    model = ConvNet((256, 256, 3))\n",
    "\n",
    "    ## Compling the model\n",
    "    model.compile(optimizer = \"adam\" , loss = loss, metrics = [\"accuracy\"]);\n",
    "\n",
    "    ## Printing the modle summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    # Loop through the indices the split() method returns\n",
    "    for index, (train_indices, val_indices) in enumerate(kfold.split(X, df['infectionType'])):\n",
    "        if (index==1): \n",
    "            break\n",
    "        print(\"Training on fold \" + str(index+1) + \"/5...\")\n",
    "        m_train= len(train_indices)\n",
    "        m_val= len(val_indices)\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y1_train, y1_val = y1[train_indices], y1[val_indices]\n",
    "        y2_train, y2_val = y2[train_indices], y2[val_indices]\n",
    "        \n",
    "        train_seq = InfectedLeavesSequence(X_train, y1_train, y2_train)\n",
    "        val_seq = InfectedLeavesSequence(X_val, y1_val, y2_val)\n",
    "\n",
    "        try:\n",
    "            hist= model.fit_generator(generator=train_seq,\n",
    "                        validation_data=val_seq,\n",
    "                        epochs= 40,\n",
    "                        \n",
    "                        )\n",
    "        \n",
    "            print(hist.history)\n",
    "        except: \n",
    "            #save model\n",
    "            model.save('model/fold'+str(index+1)+'.h5')    \n",
    "        \n",
    "        scores = model.evaluate(X_val, y_val)\n",
    "        \n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        cvscores.append(scores[1] * 100)\n",
    "        \n",
    "        #save model\n",
    "        model.save('model_fold'+(index+1)+'.h5')\n",
    "    #final accuracy\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
